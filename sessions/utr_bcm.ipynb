{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from ggplot import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "* select 5'UTRs longer than 80 nt\n",
    "* count reads aligned to these UTRs (pysam)\n",
    "* plot utr reads -bcm vs utr reads + bcm\n",
    "* select UTRs with increased number of reads upon addition of BCM (clustering?)\n",
    "* compare selected UTRs with genes upregulated in the stationary phase as discovered by DESeq2\n",
    "* compare selected UTRs with small RNA binding sites (pybedtools?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample table and barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample titles with corresponding barcodes\n",
    "samples = {\n",
    "    's9': ['ATCACG', 'ACAGTG'],\n",
    "    's9+bcm': ['CGATGT', 'GCCAAT'],\n",
    "    's17': ['TTAGGC', 'GATCAG'],\n",
    "    's17+bcm': ['TGACCA', 'TAGCTT'],\n",
    "    's19': ['CAGATC','GGCTAC'],\n",
    "    's19+bcm': ['ACTTGA', 'CTTGTA']\n",
    "}\n",
    "\n",
    "# Barcodes\n",
    "barcodes = ['ATCACG', 'ACAGTG', 'CGATGT', 'GCCAAT', 'TTAGGC', 'GATCAG', 'TGACCA', 'TAGCTT', 'CAGATC','GGCTAC', 'ACTTGA', 'CTTGTA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load counts for genes, calculate counts in UTRs longer than 80 nt\n",
    "\n",
    "Gene counts were obtained using `htseq` program against the standard NC_000913 .GFF file The was I calculate reads in UTRs here is not strand-specific. So the numbers can be confounded if there is a transcript going in the opposite direction. We can solve this later if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfm = pd.DataFrame.from_csv('../data/dfm.csv', sep='\\t')\n",
    "dfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize counts for feature length, log-transform, and take means for replicates\n",
    "\n",
    "Pseudo-counts (+1) are added during UTR reads counting to make sure we can log-transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_vars = ['TSS','TU_name','coord_5','coord_3','gene', 'UTR_length']\n",
    "value_vars = ['s9','s17','s19','s9+bcm','s17+bcm','s19+bcm']\n",
    "\n",
    "dfn = dfm.copy()\n",
    "\n",
    "# Normalize counts by gene and utr length\n",
    "def norm_orf(barcode, rec):\n",
    "    return float(rec[barcode] / abs(rec['first_gene_5'] - rec['first_gene_3']))\n",
    "\n",
    "def norm_utr(barcode, rec):\n",
    "    return float(rec['utr_{0}'.format(barcode)] / rec['UTR_length'])\n",
    "\n",
    "for barcode in barcodes:\n",
    "    dfn['orf_{0}'.format(barcode)] = dfn.apply(lambda rec: norm_orf(barcode, rec), axis=1)\n",
    "    dfn['utr_{0}'.format(barcode)] = dfn.apply(lambda rec: norm_utr(barcode, rec), axis=1)\n",
    "\n",
    "    \n",
    "df = dfn[id_vars].copy()\n",
    "# Take means across replicates according to the samples dict\n",
    "for sample, bcs in samples.items():\n",
    "    df['orf_{0}'.format(sample)] = np.log10(dfn[['orf_{0}'.format(b) for b in list(bcs)]].mean(axis=1))\n",
    "    df['utr_{0}'.format(sample)] = np.log10(dfn[['utr_{0}'.format(b) for b in list(bcs)]].mean(axis=1))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot wild type with vs without BCM\n",
    "\n",
    "Two clusters are apparent. We are after the UTRs that are upregulated by the addition of BCM (cloud of points in the left part of the plot along y=0 line and in general (significantly) above y=x line).\n",
    "\n",
    "BTW, the point size is the length of UTR. No (apparent) correlation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = ggplot(df, aes(x='utr_s9', y='utr_s9+bcm', size='UTR_length')) \\\n",
    "        + geom_point(alpha=0.1) \\\n",
    "        + geom_abline(slope=1, intercept=0, size=2.5, color='#586e75')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "Now we need a way to split the points the way we want. Let's try a bunch of clustering algorithms from `scikit-learn.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn import cluster\n",
    "from sklearn import mixture\n",
    "\n",
    "X = df.as_matrix(columns=['utr_s9', 'utr_s9+bcm'])\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "bandwidth = cluster.estimate_bandwidth(X, quantile=0.3)\n",
    "connectivity = kneighbors_graph(X, n_neighbors=20)\n",
    "connectivity = 0.05 * (connectivity + connectivity.T)\n",
    "#distances = euclidean_distances(X)\n",
    "\n",
    "gmm = mixture.GMM(n_components=2, covariance_type='full')\n",
    "\n",
    "ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "two_means = cluster.MiniBatchKMeans(n_clusters=2, batch_size=200)\n",
    "kmeans = cluster.KMeans(n_clusters=2)\n",
    "ward = cluster.AgglomerativeClustering(n_clusters=2, linkage='ward', connectivity=connectivity)\n",
    "spectral = cluster.SpectralClustering(n_clusters=2, n_neighbors=20, eigen_solver='arpack', affinity='nearest_neighbors')\n",
    "dbscan = cluster.DBSCAN(eps=.5)\n",
    "affinity_propagation = cluster.AffinityPropagation(damping=.95, preference=-200)\n",
    "average_linkage = cluster.AgglomerativeClustering(linkage='average', affinity='cityblock', n_clusters=2, connectivity=connectivity)\n",
    "\n",
    "for name, alg in [\n",
    "                    ('MiniBatchKMeans', two_means),\n",
    "                    ('KMeans', kmeans),\n",
    "                    ('AffinityPropagation', affinity_propagation),\n",
    "                    ('MeanShift', ms),\n",
    "                    ('GMM', gmm),\n",
    "                    ('SpectralClustering', spectral),\n",
    "                    ('Ward', ward),\n",
    "                    ('AgglomerativeClustering', average_linkage),\n",
    "                    ('DBSCAN', dbscan)\n",
    "                ]:\n",
    "    alg.fit(X)\n",
    "    if hasattr(alg, 'labels_'):\n",
    "        df['label'] = alg.labels_.astype(np.int)\n",
    "    else:\n",
    "        df['label'] = alg.predict(X)\n",
    "    \n",
    "    p = ggplot(df, aes(x='utr_s9', y='utr_s9+bcm', color='label')) \\\n",
    "        + geom_point(alpha=0.5) \\\n",
    "        + ggtitle(name) \\\n",
    "        + geom_abline(slope=1, intercept=0, size=2.5, color='#586e75')\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
